[2020/05/01 00:47:32] - Namespace(attack='pgd', attack_network=True, batch_size=128, black_box=False, directory='/home/metehan/deep_adv/CIFAR10/', epochs=15, epsilon=0.03137254901960784, log_interval=100, loss_scale='1.0', lr=0.1, lr_max=0.2, lr_min=0.0, master_weights=False, model='ResNetMadry', momentum=0.9, no_cuda=False, norm='inf', num_iterations=7, num_restarts=1, opt_level='O2', rand=False, save_model=False, seed=1, step_size=0.00784313725490196, test_batch_size=200, tr_alpha=0.0392156862745098, tr_attack='fgsm', tr_epsilon=0.03137254901960784, tr_norm='inf', tr_num_iterations=10, tr_num_restarts=1, tr_rand=True, tr_step_size=0.00784313725490196, train=True, weight_decay=0.0005)
[2020/05/01 00:47:32] - 

[2020/05/01 00:47:40] - ResNet(
  (norm): Normalize()
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block2): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block3): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
[2020/05/01 00:47:40] - 

[2020/05/01 00:47:40] - Epoch 	 Seconds 	 LR 	 	 Train Loss 	 Train Acc
[2020/05/01 00:47:40] - FGSM adversarial training
[2020/05/01 00:48:58] - Namespace(attack='pgd', attack_network=True, batch_size=128, black_box=False, directory='/home/metehan/deep_adv/CIFAR10/', epochs=15, epsilon=0.03137254901960784, log_interval=100, loss_scale='1.0', lr=0.1, lr_max=0.2, lr_min=0.0, master_weights=False, model='ResNetMadry', momentum=0.9, no_cuda=False, norm='inf', num_iterations=7, num_restarts=1, opt_level='O2', rand=False, save_model=False, seed=1, step_size=0.00784313725490196, test_batch_size=200, tr_alpha=0.0392156862745098, tr_attack='fgsm', tr_epsilon=0.03137254901960784, tr_norm='inf', tr_num_iterations=10, tr_num_restarts=1, tr_rand=True, tr_step_size=0.00784313725490196, train=True, weight_decay=0.0005)
[2020/05/01 00:48:58] - 

[2020/05/01 00:49:06] - ResNet(
  (norm): Normalize()
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block2): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block3): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
[2020/05/01 00:49:06] - 

[2020/05/01 00:49:06] - Epoch 	 Seconds 	 LR 	 	 Train Loss 	 Train Acc
[2020/05/01 00:49:06] - FGSM adversarial training
[2020/05/01 00:49:28] - 1 	 23 	 	 0.0267 	 2.1290 	 0.1924
[2020/05/01 00:49:28] - Test  	 loss: 1.7663 	 acc: 0.3502
[2020/05/01 00:49:51] - 2 	 22 	 	 0.0533 	 1.9675 	 0.2613
[2020/05/01 00:49:51] - Test  	 loss: 1.6823 	 acc: 0.3696
[2020/05/01 00:50:13] - 3 	 22 	 	 0.0800 	 1.9010 	 0.2827
[2020/05/01 00:50:13] - Test  	 loss: 1.5250 	 acc: 0.4480
[2020/05/01 00:50:35] - 4 	 22 	 	 0.1067 	 1.8418 	 0.3060
[2020/05/01 00:50:35] - Test  	 loss: 1.4490 	 acc: 0.4605
[2020/05/01 00:50:57] - 5 	 22 	 	 0.1333 	 1.7941 	 0.3197
[2020/05/01 00:50:57] - Test  	 loss: 1.4223 	 acc: 0.4961
[2020/05/01 00:51:18] - 6 	 22 	 	 0.1600 	 1.7501 	 0.3350
[2020/05/01 00:51:18] - Test  	 loss: 1.3155 	 acc: 0.5129
[2020/05/01 00:51:40] - 7 	 22 	 	 0.1867 	 1.7115 	 0.3494
[2020/05/01 00:51:40] - Test  	 loss: 1.3305 	 acc: 0.5444
[2020/05/01 00:52:02] - 8 	 22 	 	 0.1867 	 1.6793 	 0.3636
[2020/05/01 00:52:02] - Test  	 loss: 1.2806 	 acc: 0.5357
[2020/05/01 00:52:24] - 9 	 22 	 	 0.1600 	 1.6480 	 0.3741
[2020/05/01 00:52:24] - Test  	 loss: 1.2081 	 acc: 0.5756
[2020/05/01 00:52:45] - 10 	 21 	 	 0.1333 	 1.6147 	 0.3868
[2020/05/01 00:52:45] - Test  	 loss: 1.1456 	 acc: 0.6107
[2020/05/01 00:53:06] - 11 	 21 	 	 0.1067 	 1.5913 	 0.3970
[2020/05/01 00:53:06] - Test  	 loss: 1.1331 	 acc: 0.5935
[2020/05/01 00:53:27] - 12 	 22 	 	 0.0800 	 1.5571 	 0.4095
[2020/05/01 00:53:27] - Test  	 loss: 1.1056 	 acc: 0.6144
[2020/05/01 00:53:47] - 13 	 20 	 	 0.0533 	 1.5196 	 0.4225
[2020/05/01 00:53:47] - Test  	 loss: 1.0238 	 acc: 0.6545
[2020/05/01 00:54:11] - 14 	 23 	 	 0.0267 	 1.4765 	 0.4376
[2020/05/01 00:54:11] - Test  	 loss: 0.9588 	 acc: 0.6813
[2020/05/01 00:54:32] - 15 	 22 	 	 0.0000 	 1.4068 	 0.4627
[2020/05/01 00:54:32] - Test  	 loss: 0.9051 	 acc: 0.7064
[2020/05/01 00:54:41] - Attack  	 loss: 1.5676 	 acc: 0.4007
[2020/05/01 01:14:52] - Namespace(attack='pgd', attack_network=True, batch_size=128, black_box=False, directory='/home/metehan/deep_adv/CIFAR10/', epochs=30, epsilon=0.03137254901960784, log_interval=100, loss_scale='1.0', lr=0.1, lr_max=0.2, lr_min=0.0, master_weights=False, model='ResNetMadry', momentum=0.9, no_cuda=False, norm='inf', num_iterations=7, num_restarts=1, opt_level='O2', rand=False, save_model=False, seed=1, step_size=0.00784313725490196, test_batch_size=200, tr_alpha=0.0392156862745098, tr_attack='fgsm', tr_epsilon=0.03137254901960784, tr_norm='inf', tr_num_iterations=10, tr_num_restarts=1, tr_rand=True, tr_step_size=0.00784313725490196, train=True, weight_decay=0.0005)
[2020/05/01 01:14:52] - 

[2020/05/01 01:14:57] - ResNet(
  (norm): Normalize()
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block2): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (block3): Sequential(
    (0): ResidualUnit(
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (1): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (2): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (3): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (4): ResidualUnit(
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
[2020/05/01 01:14:57] - 

[2020/05/01 01:14:57] - Epoch 	 Seconds 	 LR 	 	 Train Loss 	 Train Acc
[2020/05/01 01:14:57] - FGSM adversarial training
[2020/05/01 01:15:19] - 1 	 23 	 	 0.0133 	 2.1599 	 0.1766
[2020/05/01 01:15:19] - Test  	 loss: 1.7449 	 acc: 0.3510
[2020/05/01 01:15:42] - 2 	 22 	 	 0.0267 	 1.9846 	 0.2553
[2020/05/01 01:15:42] - Test  	 loss: 1.7020 	 acc: 0.3758
[2020/05/01 01:16:04] - 3 	 22 	 	 0.0400 	 1.9154 	 0.2784
[2020/05/01 01:16:04] - Test  	 loss: 1.5492 	 acc: 0.4418
[2020/05/01 01:16:25] - 4 	 21 	 	 0.0533 	 1.8582 	 0.2986
[2020/05/01 01:16:25] - Test  	 loss: 1.4870 	 acc: 0.4571
[2020/05/01 01:16:46] - 5 	 21 	 	 0.0667 	 1.8106 	 0.3134
[2020/05/01 01:16:46] - Test  	 loss: 1.4285 	 acc: 0.4779
[2020/05/01 01:17:08] - 6 	 21 	 	 0.0800 	 1.7723 	 0.3281
[2020/05/01 01:17:08] - Test  	 loss: 1.3810 	 acc: 0.4850
[2020/05/01 01:17:29] - 7 	 22 	 	 0.0933 	 1.7284 	 0.3429
[2020/05/01 01:17:29] - Test  	 loss: 1.3797 	 acc: 0.5183
[2020/05/01 01:17:50] - 8 	 21 	 	 0.1067 	 1.6943 	 0.3566
[2020/05/01 01:17:50] - Test  	 loss: 1.3182 	 acc: 0.5197
[2020/05/01 01:18:13] - 9 	 22 	 	 0.1200 	 1.6662 	 0.3687
[2020/05/01 01:18:13] - Test  	 loss: 1.2644 	 acc: 0.5458
[2020/05/01 01:18:35] - 10 	 22 	 	 0.1333 	 1.6432 	 0.3748
[2020/05/01 01:18:35] - Test  	 loss: 1.2037 	 acc: 0.5852
[2020/05/01 01:18:57] - 11 	 23 	 	 0.1467 	 1.6326 	 0.3810
[2020/05/01 01:18:57] - Test  	 loss: 1.1849 	 acc: 0.5702
[2020/05/01 01:19:18] - 12 	 21 	 	 0.1600 	 1.6143 	 0.3886
[2020/05/01 01:19:18] - Test  	 loss: 1.2170 	 acc: 0.5777
[2020/05/01 01:19:40] - 13 	 22 	 	 0.1733 	 1.6037 	 0.3918
[2020/05/01 01:19:40] - Test  	 loss: 1.1765 	 acc: 0.5826
[2020/05/01 01:20:01] - 14 	 21 	 	 0.1867 	 1.5948 	 0.3949
[2020/05/01 01:20:01] - Test  	 loss: 1.2093 	 acc: 0.5654
[2020/05/01 01:20:22] - 15 	 21 	 	 0.2000 	 1.5840 	 0.3995
[2020/05/01 01:20:22] - Test  	 loss: 1.2042 	 acc: 0.5649
[2020/05/01 01:20:43] - 16 	 21 	 	 0.1867 	 1.5761 	 0.4032
[2020/05/01 01:20:43] - Test  	 loss: 1.1510 	 acc: 0.6183
[2020/05/01 01:21:04] - 17 	 20 	 	 0.1733 	 1.5595 	 0.4081
[2020/05/01 01:21:04] - Test  	 loss: 1.1031 	 acc: 0.6358
[2020/05/01 01:21:25] - 18 	 21 	 	 0.1600 	 1.5439 	 0.4138
[2020/05/01 01:21:25] - Test  	 loss: 1.0751 	 acc: 0.6361
[2020/05/01 01:21:45] - 19 	 21 	 	 0.1467 	 1.5294 	 0.4193
[2020/05/01 01:21:45] - Test  	 loss: 1.0508 	 acc: 0.6481
[2020/05/01 01:22:07] - 20 	 21 	 	 0.1333 	 1.5199 	 0.4256
[2020/05/01 01:22:07] - Test  	 loss: 1.1078 	 acc: 0.6483
[2020/05/01 01:22:28] - 21 	 21 	 	 0.1200 	 1.5046 	 0.4297
[2020/05/01 01:22:28] - Test  	 loss: 1.0463 	 acc: 0.6497
[2020/05/01 01:22:49] - 22 	 21 	 	 0.1067 	 1.4868 	 0.4353
[2020/05/01 01:22:49] - Test  	 loss: 1.0517 	 acc: 0.6407
[2020/05/01 01:23:10] - 23 	 21 	 	 0.0933 	 1.4780 	 0.4393
[2020/05/01 01:23:10] - Test  	 loss: 1.0186 	 acc: 0.6384
[2020/05/01 01:23:31] - 24 	 21 	 	 0.0800 	 1.4584 	 0.4446
[2020/05/01 01:23:31] - Test  	 loss: 1.0339 	 acc: 0.6391
[2020/05/01 01:23:52] - 25 	 21 	 	 0.0667 	 1.4384 	 0.4537
[2020/05/01 01:23:52] - Test  	 loss: 0.9363 	 acc: 0.6898
[2020/05/01 01:24:13] - 26 	 21 	 	 0.0533 	 1.4154 	 0.4621
[2020/05/01 01:24:13] - Test  	 loss: 0.9190 	 acc: 0.6914
[2020/05/01 01:24:57] - 27 	 43 	 	 0.0400 	 1.3910 	 0.4722
[2020/05/01 01:24:57] - Test  	 loss: 0.8879 	 acc: 0.7088
[2020/05/01 01:25:39] - 28 	 43 	 	 0.0267 	 1.3605 	 0.4805
[2020/05/01 01:25:39] - Test  	 loss: 0.8702 	 acc: 0.7126
[2020/05/01 01:26:24] - 29 	 45 	 	 0.0133 	 1.3162 	 0.4954
[2020/05/01 01:26:24] - Test  	 loss: 0.8181 	 acc: 0.7328
[2020/05/01 01:27:07] - 30 	 42 	 	 0.0000 	 1.2627 	 0.5141
[2020/05/01 01:27:07] - Test  	 loss: 0.7579 	 acc: 0.7573
[2020/05/01 01:27:22] - Attack  	 loss: 1.5021 	 acc: 0.4285
